{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25e2b410-d826-472e-bc3b-c937fd7dbf17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql\n",
    "\n",
    "input_path=\"s3://ayush-varma/Input/StreamingData/\"\n",
    "checkpoint_path=\"s3://ayush-varma/output/checkpoint/\"\n",
    "\n",
    "\n",
    "raw_df = (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"cloudFiles.schemaLocation\", checkpoint_path)\n",
    "    .option(\"inferSchema\", 'True')\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\",\"rescue\" )\n",
    "    .load(input_path)\n",
    ")\n",
    "\n",
    "display(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df2e478-fd37-426c-8cc4-aa901fe94668",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import input_file_name, count\n",
    "\n",
    "# inserting a new column displaying the source file name\n",
    "files_df= (\n",
    "    raw_df.withColumn(\"file_source_name\", input_file_name())\n",
    ")\n",
    "\n",
    "display(files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af5ecff9-51cf-4ca2-ae97-8067476691f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "files_df.writeStream \\\n",
    "    .format('delta') \\\n",
    "    .option('checkpointLocation', checkpoint_path) \\\n",
    "    .option(\"mergeschema\", \"true\") \\\n",
    "    .queryName('employee-delta') \\\n",
    "    .trigger(processingTime=\"2 seconds\") \\\n",
    "    .table('employee')"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Streaming using S3 bucket",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
